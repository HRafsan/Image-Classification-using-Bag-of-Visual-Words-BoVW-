{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfG_todxMT6c"
      },
      "source": [
        "Image Classification using Bag of Visual Words (BoVW)\n",
        "====\n",
        "- In this notebook, we will classify the images into five categories (aeroplane, backgrounds, car, horse, motorcycle, person) using Bag of Visual Word (BoVW) and Support Vector Machine (SVM).\n",
        "\n",
        "- We will extract the SIFT descriptors from the images and construct a codebook. After that, we will encode the images to histogram features using codebook, and train the classifier using those features.\n",
        "\n",
        "-  We will then extract dense SIFT descriptors from the images, reconstruct the codebook, then train the classifier again using the new codebook. Then using this codebook we will also test the performance of spatial pyramid matching by training the classifier using that method\n",
        "\n",
        "-  Finally, we will use Non-Linear SVM to train the classifier, and test its performance with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RysBzJQFeIkg"
      },
      "source": [
        "## Step 0: Set the enviroments\n",
        "First we set up the enviroments to train this model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26drrtRufRbK"
      },
      "source": [
        "###  0-1: Download cyvlfeat library & conda\n",
        "\n",
        "First we download cyvlfeat library and conda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEjDierhsAZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3100676-42ed-4f86-c687-1730a0b0db11"
      },
      "source": [
        "# install conda on colab\n",
        "!pip install -q condacolab numpy==1.26.4\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge cyvlfeat==0.7.1  -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3985gb9aOypG"
      },
      "source": [
        "###  0-2: Connecting to Google Drive.\n",
        "\n",
        "It is required for loading the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKffRxrvDSJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a73d69-9304-47f5-dac6-b349ee9a65b2"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bypm5tteROL"
      },
      "source": [
        "### 0-3: Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W88TOaCsxpfw"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cyvlfeat\n",
        "import time\n",
        "import scipy\n",
        "import multiprocessing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xv7wrsXBO-w"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTq8GkOJBN4b"
      },
      "source": [
        "def euclidean_dist(x, y):\n",
        "    \"\"\"\n",
        "    :param x: [m, d]\n",
        "    :param y: [n, d]\n",
        "    :return:[m, n]\n",
        "    \"\"\"\n",
        "    m, n = x.shape[0], y.shape[0]\n",
        "    eps = 1e-6\n",
        "\n",
        "    xx = np.tile(np.power(x, 2).sum(axis=1), (n,1)) #[n, m]\n",
        "    xx = np.transpose(xx) # [m, n]\n",
        "    yy = np.tile(np.power(y, 2).sum(axis=1), (m,1)) #[m, n]\n",
        "    xy = np.matmul(x, np.transpose(y)) # [m, n]\n",
        "    dist = np.sqrt(xx + yy - 2*xy + eps)\n",
        "\n",
        "    return dist\n",
        "\n",
        "def read_img(image_path):\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    img = img.resize((240, 240))\n",
        "    return np.float32(np.array(img)/255.)\n",
        "\n",
        "def read_txt(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "    return data.split()\n",
        "\n",
        "def dataset_setup(data_dir):\n",
        "    train_file_list = []\n",
        "    val_file_list = []\n",
        "\n",
        "    for class_name in ['aeroplane','horse','motorbike']:\n",
        "        train_txt_path = os.path.join(data_dir, class_name+'_train.txt')\n",
        "        train_file_list.append(np.array(read_txt(train_txt_path)))\n",
        "        val_txt_path = os.path.join(data_dir, class_name+'_val.txt')\n",
        "        val_file_list.append(np.array(read_txt(val_txt_path)))\n",
        "\n",
        "    train_file_list = np.unique(np.concatenate(train_file_list))\n",
        "    val_file_list = np.unique(np.concatenate(val_file_list))\n",
        "\n",
        "    f = open(os.path.join(data_dir, \"train.txt\"), 'w')\n",
        "    non_existing_data = []\n",
        "    for i in range(train_file_list.shape[0]):\n",
        "        if os.path.exists(os.path.join(data_dir+'/images', train_file_list[i]+'.jpg')):\n",
        "            data = \"%s\\n\" % train_file_list[i]\n",
        "            f.write(data)\n",
        "        else:\n",
        "            non_existing_data.append(train_file_list[i])\n",
        "    f.close()\n",
        "    print(f\"{len(non_existing_data)} images missing: {non_existing_data}/{train_file_list.shape[0]}\")\n",
        "\n",
        "    f = open(os.path.join(data_dir, \"val.txt\"), 'w')\n",
        "    non_existing_data = []\n",
        "    for i in range(val_file_list.shape[0]):\n",
        "        if os.path.exists(os.path.join(data_dir+'/images', val_file_list[i]+'.jpg')):\n",
        "            data = \"%s\\n\" % val_file_list[i]\n",
        "            f.write(data)\n",
        "        else:\n",
        "            non_existing_data.append(val_file_list[i])\n",
        "    f.close()\n",
        "    print(f\"{len(non_existing_data)} images missing: {non_existing_data}/{val_file_list.shape[0]}\")\n",
        "\n",
        "def load_train_data(data_dir):\n",
        "    dataset_setup(data_dir)\n",
        "    num_proc = 12 # num_process\n",
        "\n",
        "    txt_path = os.path.join(data_dir, 'train.txt')\n",
        "    file_list = read_txt(txt_path)\n",
        "    image_paths = [os.path.join(data_dir+'/images', file_name+'.jpg') for file_name in file_list]\n",
        "    with multiprocessing.Pool(num_proc) as pool:\n",
        "      imgs = pool.map(read_img, image_paths)\n",
        "      imgs = np.array(imgs)\n",
        "      idxs = np.array(file_list)\n",
        "\n",
        "    return imgs, idxs\n",
        "\n",
        "def load_val_data(data_dir):\n",
        "    dataset_setup(data_dir)\n",
        "    num_proc = 12 # num_process\n",
        "\n",
        "    txt_path = os.path.join(data_dir, 'val.txt')\n",
        "    file_list = read_txt(txt_path)\n",
        "    image_paths = [os.path.join(data_dir+'/images', file_name+'.jpg') for file_name in file_list]\n",
        "    with multiprocessing.Pool(num_proc) as pool:\n",
        "      imgs = pool.map(read_img, image_paths)\n",
        "      imgs = np.array(imgs)\n",
        "      idxs = np.array(file_list)\n",
        "\n",
        "    return imgs, idxs\n",
        "\n",
        "def get_labels(idxs, target_idxs):\n",
        "    \"\"\"\n",
        "    Get the labels from file index(name).\n",
        "\n",
        "    :param idxs(numpy.array): file index(name). shape:[num_images, ]\n",
        "    :param target_idxs(numpy.array): target index(name). shape:[num_target,]\n",
        "    :return(numpy.array): Target label(Binary label consisting of True and False). shape:[num_images,]\n",
        "    \"\"\"\n",
        "    return np.isin(idxs, target_idxs)\n",
        "\n",
        "def load_train_idxs(data_dir):\n",
        "    txt_path = os.path.join(data_dir, 'train.txt')\n",
        "    train_idxs = np.array(read_txt(txt_path))\n",
        "    return train_idxs\n",
        "\n",
        "def load_val_idxs(data_dir):\n",
        "    txt_path = os.path.join(data_dir, 'val.txt')\n",
        "    val_idxs = np.array(read_txt(txt_path))\n",
        "    return val_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c5F-N9wfzZW"
      },
      "source": [
        "## Step 1: Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYFEIkL24nJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915aa0ef-7fa5-4359-fddd-15269ea576bf"
      },
      "source": [
        "'''\n",
        "Setting the data path for loading images & labels.\n",
        "'''\n",
        "\n",
        "%env CS_DATA_DIR= /gdrive/MyDrive/Computer vision\n",
        "\n",
        "!mkdir -p $CS_DATA_DIR\n",
        "\n",
        "# MODIFY_THIS\n",
        "os.chdir(os.environ[\"CS_DATA_DIR\"])\n",
        "!wget http://www.di.ens.fr/willow/events/cvml2013/materials/practicals/category-level/practical-category-recognition-2013a-data-only.tar.gz\n",
        "!tar -zxf practical-category-recognition-2013a-data-only.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CS_DATA_DIR=/gdrive/MyDrive/Computer vision\n",
            "--2025-04-09 05:17:17--  http://www.di.ens.fr/willow/events/cvml2013/materials/practicals/category-level/practical-category-recognition-2013a-data-only.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/willow/events/cvml2013/materials/practicals/category-level/practical-category-recognition-2013a-data-only.tar.gz [following]\n",
            "--2025-04-09 05:17:17--  https://www.di.ens.fr/willow/events/cvml2013/materials/practicals/category-level/practical-category-recognition-2013a-data-only.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘practical-category-recognition-2013a-data-only.tar.gz’\n",
            "\n",
            "practical-category-     [                <=> ] 964.15M  4.16MB/s    in 3m 48s  \n",
            "\n",
            "2025-04-09 05:21:05 (4.22 MB/s) - ‘practical-category-recognition-2013a-data-only.tar.gz’ saved [1010984641]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GW7H_2iPxzb"
      },
      "source": [
        "category = ['aeroplane', 'horse', 'motorbike']\n",
        "data_dir = os.path.join(os.environ[\"CS_DATA_DIR\"], \"practical-category-recognition-2013a\", \"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX17mbhpXrNd"
      },
      "source": [
        "## Step 2: Bag of Visual Words (BoVW) Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QuLZmSxX2l5"
      },
      "source": [
        "### 2-1: SIFT descriptor extraction & Saving the descriptors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EWqpgbOV6yE"
      },
      "source": [
        "def SIFT_extraction(imgs):\n",
        "    \"\"\"\n",
        "    Extract Local SIFT descriptors from images using cyvlfeat.sift.sift().\n",
        "    Refering to to https://github.com/menpo/cyvlfeat\n",
        "\n",
        "    :param imgs(numpy.array): Gray-scale images in Numpy array format. shape:[num_images, width_size, height_size]\n",
        "    :return(numpy.array): SIFT descriptors. shape:[num_images, ], **ndarray with object(descripotrs)**\n",
        "    \"\"\"\n",
        "    descriptors = []\n",
        "    for i in range(len(imgs)):\n",
        "        frame, descriptor = cyvlfeat.sift.sift(imgs[i], compute_descriptor=True, float_descriptors=True)\n",
        "        descriptors.append(descriptor)\n",
        "    return np.array(descriptors, dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVgUvbVYS2x"
      },
      "source": [
        "### 2-2: Codebook(Bag of Visual Words) construction\n",
        "In this step, we will construct the codebook using K-means clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLFB9eaw95zo"
      },
      "source": [
        "def get_codebook(des, k):\n",
        "    \"\"\"\n",
        "    Constructing the codebook with visual codewords using k-means clustering.\n",
        "    In this step, we use cyvlfeat.kmeans.kmeans().\n",
        "    Refering to to https://github.com/menpo/cyvlfeat\n",
        "\n",
        "    :param des(numpy.array): Descriptors. shape:[num_images, ]\n",
        "    :param k(int): Number of visual words.\n",
        "    :return(numpy.array): Bag of visual words shape:[k, 128]\n",
        "    \"\"\"\n",
        "    descriptors = np.concatenate(des, axis = 0)\n",
        "    codebook = cyvlfeat.kmeans.kmeans(descriptors, k)\n",
        "    return codebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH92-UOaYiM2"
      },
      "source": [
        "### 2-3: Encoding images to histogram feature based on codewords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPQErulqCEKv"
      },
      "source": [
        "def extract_features(des, codebook):\n",
        "    \"\"\"\n",
        "    Constructing the Bag-of-visual-Words histogram features for images using the codebook.\n",
        "\n",
        "    :param des(numpy.array): Descriptors.  shape:[num_images,]\n",
        "    :param codebook(numpy.array): Bag of visual words. shape:[k, 128]\n",
        "    :return(numpy.array): Bag of visual words shape:[num_images, k]\n",
        "    \"\"\"\n",
        "    histogram = np.zeros(shape=(len(des), len(codebook)))\n",
        "    for i in range(len(des)):\n",
        "        descriptors = des[i]\n",
        "        distances = euclidean_dist(codebook, descriptors)\n",
        "        index = np.argmin(distances, axis = 0)\n",
        "        for j in index:\n",
        "          histogram[i][j] += 1\n",
        "    return histogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwCm_b3YwYe"
      },
      "source": [
        "## Step 3: Training the classifiers\n",
        "Training a classifier using the sklearn library (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gOjAvXXGJy"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkFInH3bDJPV"
      },
      "source": [
        "def train_classifier(features, labels, svm_params):\n",
        "    \"\"\"\n",
        "    Training the SVM classifier using sklearn.svm.svc()\n",
        "    Refering to https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "    :param features(numpy.array): Historgram representation. shape:[num_images, dim_feature]\n",
        "    :param labels(numpy.array): Target label(binary). shape:[num_images,]\n",
        "    :param svm_params(dict): parameters for classifier training.\n",
        "        ['C'](float): Regularization parameter.\n",
        "        ['kernel'](str): Specifies the kernel type to be used in the algorithm.\n",
        "    :return(sklearn.svm.SVC): Trained classifier\n",
        "    \"\"\"\n",
        "    Classifier = SVC(**svm_params)\n",
        "    Classifier.fit(features, labels)\n",
        "    return Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNvZlykjWfyn"
      },
      "source": [
        "def Trainer(feat_params, svm_params):\n",
        "    \"\"\"\n",
        "    Training the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to save codebooks & results.\n",
        "\n",
        "    :param svm_params(dict): parameters for classifier training.\n",
        "        ['C'](float): Regularization parameter.\n",
        "        ['kernel'](str): Specifies the kernel type to be used in the algorithm.\n",
        "\n",
        "    :return(sklearn.svm.SVC): trained classifier\n",
        "    \"\"\"\n",
        "\n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "\n",
        "    if not os.path.isdir(result_dir):\n",
        "        os.mkdir(result_dir)\n",
        "\n",
        "    print(\"Load the training data...\")\n",
        "    start_time = time.time()\n",
        "    train_imgs, train_idxs = load_train_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    try:\n",
        "      train_des = np.load(os.path.join(result_dir, 'train_des.npy'),\n",
        "                          allow_pickle=True)\n",
        "      print(\"Successfully loaded the local descriptors\")\n",
        "    except:\n",
        "      print(\"Extract the local descriptors...\")\n",
        "      start_time = time.time()\n",
        "      train_des = extractor(train_imgs)\n",
        "      np.save(os.path.join(result_dir, 'train_des.npy'), train_des)\n",
        "      print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    if train_des.dtype not in [np.float32, np.float64]:\n",
        "      try:\n",
        "        train_des = train_des.astype(np.float32)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    del train_imgs\n",
        "\n",
        "    try:\n",
        "      codebook = np.load(os.path.join(result_dir, 'codebook.npy'),\n",
        "                          allow_pickle=True)\n",
        "      print(\"Successfully loaded the bag of visual words\")\n",
        "    except:\n",
        "      print(\"Construct the bag of visual words...\")\n",
        "      start_time = time.time()\n",
        "      codebook = get_codebook(train_des, k)\n",
        "      np.save(os.path.join(result_dir, 'codebook.npy'), codebook)\n",
        "      print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()\n",
        "    train_features = extract_features(train_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'train_features.npy'), train_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del train_des, codebook\n",
        "\n",
        "    print('Train the classifiers...')\n",
        "    accuracy = 0\n",
        "    models = {}\n",
        "\n",
        "    for class_name in tqdm(category):\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_train.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(train_idxs, target_idxs)\n",
        "\n",
        "        models[class_name] = train_classifier(train_features, target_labels, svm_params)\n",
        "        train_accuracy = models[class_name].score(train_features, target_labels)\n",
        "        print('{} Classifier train accuracy:  {:.4f}'.format(class_name, train_accuracy))\n",
        "        accuracy += train_accuracy\n",
        "\n",
        "    print('Average train accuracy: {:.4f}'.format(accuracy/len(category)))\n",
        "    del train_features, target_labels, target_idxs\n",
        "\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkM12brUWjLs"
      },
      "source": [
        "feat_params = {'extractor': SIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'sift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ULB-kc5jpk"
      },
      "source": [
        "- Below code will take about 2~10 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_QngFiWlRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c64ec1-5b4a-456c-c413-0a26fc9ee704"
      },
      "source": [
        "models = Trainer(feat_params, svm_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the training data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "2.9784 seconds\n",
            "Successfully loaded the local descriptors\n",
            "Successfully loaded the bag of visual words\n",
            "Extract the image features...\n",
            "2.3665 seconds\n",
            "Train the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:00<00:00,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier train accuracy:  1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse Classifier train accuracy:  1.0000\n",
            "motorbike Classifier train accuracy:  1.0000\n",
            "Average train accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLnPCHFOalSk"
      },
      "source": [
        "## Step 4: Testing the classifier on validation set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EN0ZUiXWoI3"
      },
      "source": [
        "def Test(feat_params, models):\n",
        "    \"\"\"\n",
        "    Test the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to load codebooks & save results.\n",
        "\n",
        "    :param models(dict): dict of classifiers(sklearn.svm.SVC)\n",
        "    \"\"\"\n",
        "\n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "\n",
        "    print(\"Load the validation data...\")\n",
        "    start_time = time.time()\n",
        "    val_imgs, val_idxs = load_val_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    try:\n",
        "      val_des = np.load(os.path.join(result_dir, 'val_des.npy'),\n",
        "                        allow_pickle=True)\n",
        "    except:\n",
        "      print(\"Extract the local descriptors...\")\n",
        "      start_time = time.time()\n",
        "      val_des = extractor(val_imgs)\n",
        "      np.save(os.path.join(result_dir, 'val_des.npy'), val_des)\n",
        "      print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    if val_des.dtype not in [np.float32, np.float64]:\n",
        "      try:\n",
        "        val_des = val_des.astype(np.float32)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    del val_imgs\n",
        "    codebook = np.load(os.path.join(result_dir, 'codebook.npy'),\n",
        "                       allow_pickle=True)\n",
        "\n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    val_features = extract_features(val_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'val_features.npy'), val_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del val_des, codebook\n",
        "\n",
        "    print('Test the classifiers...')\n",
        "    accuracy = 0\n",
        "    for class_name in tqdm(category):\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_val.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(val_idxs, target_idxs)\n",
        "\n",
        "        val_accuracy = models[class_name].score(val_features, target_labels)\n",
        "        print('{} Classifier validation accuracy:  {:.4f}'.format(class_name, val_accuracy))\n",
        "        accuracy += val_accuracy\n",
        "\n",
        "    del val_features, target_idxs, target_labels\n",
        "\n",
        "    print('Average validation accuracy: {:.4f}'.format(accuracy/len(category)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z80KKyn7Ytfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e570639-2dac-4659-fcc4-4624ba2adcd6"
      },
      "source": [
        "Test(feat_params, models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the validation data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "2.9411 seconds\n",
            "Extract the image features...\n",
            "2.0054 seconds\n",
            "Test the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 2/3 [00:00<00:00, 13.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier validation accuracy:  0.7970\n",
            "horse Classifier validation accuracy:  0.6491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 3/3 [00:00<00:00, 14.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorbike Classifier validation accuracy:  0.7168\n",
            "Average validation accuracy: 0.7210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3X0BFLm756K"
      },
      "source": [
        "## Step 5: Implementing Dense SIFT\n",
        "Modifying the feature extractor using the dense SIFT and evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaY4kqQE8PXK"
      },
      "source": [
        "def DenseSIFT_extraction(imgs):\n",
        "    \"\"\"\n",
        "    Extracting Dense SIFT descriptors from images using cyvlfeat.sift.dsift().\n",
        "    Refering to https://github.com/menpo/cyvlfeat\n",
        "\n",
        "    :param train_imgs(numpy.array): Gray-scale images in Numpy array format. shape:[num_images, width_size, height_size]\n",
        "    :return(numpy.array): Dense SIFT descriptors. shape:[num_images, num_des_of_each_img, 128]\n",
        "    \"\"\"\n",
        "    descriptors = []\n",
        "    for i in range(len(imgs)):\n",
        "        frame, descriptor = cyvlfeat.sift.dsift(imgs[i], step = 12, float_descriptors=True)\n",
        "        descriptors.append(descriptor)\n",
        "    return np.array(descriptors, dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyhyW4yYEFxz"
      },
      "source": [
        "feat_params = {'extractor': DenseSIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'dsift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPYn8ubgEuq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5223d0-ba98-413a-8a0f-bef05ff0ed60"
      },
      "source": [
        "models = Trainer(feat_params, svm_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the training data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "2.4614 seconds\n",
            "Successfully loaded the local descriptors\n",
            "Successfully loaded the bag of visual words\n",
            "Extract the image features...\n",
            "2.0652 seconds\n",
            "Train the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 2/3 [00:00<00:00, 12.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier train accuracy:  1.0000\n",
            "horse Classifier train accuracy:  1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 3/3 [00:00<00:00, 11.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorbike Classifier train accuracy:  1.0000\n",
            "Average train accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b3X3gYHErl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e29cbd-6018-4017-f8e4-f9c3602b22d7"
      },
      "source": [
        "Test(feat_params, models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the validation data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "3.7039 seconds\n",
            "Extract the image features...\n",
            "2.6293 seconds\n",
            "Test the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 24.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier validation accuracy:  0.8596\n",
            "horse Classifier validation accuracy:  0.7343\n",
            "motorbike Classifier validation accuracy:  0.7393\n",
            "Average validation accuracy: 0.7778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWyoU1yG7qhf"
      },
      "source": [
        "## Step 6: Implementing the Spatial Pyramid\n",
        "Modifying the feature extractor using the spatial pyramid matching and evaluate the performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJJpyKo98QQp"
      },
      "source": [
        "def SpatialPyramid(des, codebook):\n",
        "    \"\"\"\n",
        "    Extracting image representation with Spatial Pyramid Matching using the DenseSIFT descriptors & codebook.\n",
        "\n",
        "    :param des: numpy.array, DenseSIFT Descriptors.  Shape: [num_images, num_des_of_each_img, 128]\n",
        "    :param codebook: numpy.array, Bag of visual words. Shape: [k, 128]\n",
        "    :return: numpy.array, Image feature using Spatial Pyramid Matching. Shape: [num_images, features_dim]\n",
        "    \"\"\"\n",
        "    features_dim = 0\n",
        "    dimension = 1\n",
        "    while dimension != 16:\n",
        "        features_dim += dimension ** 2\n",
        "        dimension = dimension * 2\n",
        "\n",
        "    histogram = np.zeros((len(des), len(codebook) * features_dim))\n",
        "\n",
        "    for i in range(len(des)):\n",
        "        descriptors = np.array(des[i], dtype=float)\n",
        "        num_des, dim = descriptors.shape\n",
        "        Normalizer = 1\n",
        "        level = 0\n",
        "        while Normalizer != 16:\n",
        "            for j in range(Normalizer):\n",
        "                for k in range(Normalizer):\n",
        "                    cell_descriptors = descriptors[j*(descriptors.shape[0]//Normalizer): (j + 1) * (descriptors.shape[0]//Normalizer), k * (descriptors.shape[1]//Normalizer) : (k + 1) * (descriptors.shape[1]//Normalizer)]\n",
        "\n",
        "                    distances = euclidean_dist(cell_descriptors, codebook[:, k *  (descriptors.shape[1]//Normalizer): (k + 1) * (descriptors.shape[1]//Normalizer)])\n",
        "                    indices = np.argmin(distances, axis=1)\n",
        "                    cell_hist = np.bincount(indices, minlength=len(codebook)) / Normalizer\n",
        "\n",
        "                    offset = 0\n",
        "                    for l in range(level):\n",
        "                        offset += (2 ** l) ** 2 * len(codebook)\n",
        "                    cell_index = j * Normalizer + k\n",
        "                    pos = offset + cell_index * len(codebook)\n",
        "                    histogram[i, pos : pos + len(codebook)] += cell_hist\n",
        "            Normalizer = Normalizer * 2\n",
        "            level += 1\n",
        "    return histogram\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAVKLXXyx2NE"
      },
      "source": [
        "def SP_Trainer(feat_params, svm_params):\n",
        "    \"\"\"\n",
        "    Train the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to save codebooks & results.\n",
        "\n",
        "    :param svm_params(dict): parameters for classifier training.\n",
        "        ['C'](float): Regularization parameter.\n",
        "        ['kernel'](str): Specifies the kernel type to be used in the algorithm.\n",
        "\n",
        "    :return(sklearn.svm.SVC): trained classifier\n",
        "    \"\"\"\n",
        "\n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "\n",
        "    if not os.path.isdir(result_dir):\n",
        "        os.mkdir(result_dir)\n",
        "\n",
        "    print(\"Load the training data...\")\n",
        "    start_time = time.time()\n",
        "    train_imgs, train_idxs = load_train_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    print(\"Extract the local descriptors...\")\n",
        "    start_time = time.time()\n",
        "    #train_des = extractor(train_imgs)\n",
        "    #np.save(os.path.join(result_dir, 'train_des.npy'), train_des)\n",
        "    train_des = np.load(os.path.join(result_dir, 'train_des.npy'), allow_pickle=True)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del train_imgs\n",
        "\n",
        "    if train_des.dtype not in [np.float32, np.float64]:\n",
        "      try:\n",
        "        train_des = train_des.astype(np.float32)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    print(\"Construct the bag of visual words...\")\n",
        "    start_time = time.time()\n",
        "    codebook = np.load(os.path.join(result_dir, 'codebook.npy'),\n",
        "                       allow_pickle=True)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()\n",
        "    train_features = SpatialPyramid(train_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'train_features.npy'), train_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del train_des, codebook\n",
        "\n",
        "    print('Train the classifiers...')\n",
        "    accuracy = 0\n",
        "    models = {}\n",
        "\n",
        "    for class_name in tqdm(category):\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_train.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(train_idxs, target_idxs)\n",
        "\n",
        "        models[class_name] = train_classifier(train_features, target_labels, svm_params)\n",
        "        train_accuracy = models[class_name].score(train_features, target_labels)\n",
        "        print('{} Classifier train accuracy:  {:.4f}'.format(class_name, train_accuracy))\n",
        "        accuracy += train_accuracy\n",
        "\n",
        "    print('Average train accuracy: {:.4f}'.format(accuracy/len(category)))\n",
        "    del train_features, target_labels, target_idxs\n",
        "\n",
        "    return models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q--UT0fyEyc"
      },
      "source": [
        "def SP_Test(feat_params, models):\n",
        "    \"\"\"\n",
        "    Test the SVM classifier.\n",
        "\n",
        "    :param feat_params(dict): parameters for feature extraction.\n",
        "        ['extractor'](function pointer): function for extrat local descriptoers. (e.g. SIFT_extraction, DenseSIFT_extraction, etc)\n",
        "        ['num_codewords'](int):\n",
        "        ['result_dir'](str): Diretory to load codebooks & save results.\n",
        "\n",
        "    :param models(dict): dict of classifiers(sklearn.svm.SVC)\n",
        "    \"\"\"\n",
        "\n",
        "    extractor = feat_params['extractor']\n",
        "    k = feat_params['num_codewords']\n",
        "    result_dir = feat_params['result_dir']\n",
        "\n",
        "    print(\"Load the validation data...\")\n",
        "    start_time = time.time()\n",
        "    val_imgs, val_idxs = load_val_data(data_dir)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    print(\"Extract the local descriptors...\")\n",
        "    start_time = time.time()\n",
        "    val_des = extractor(val_imgs)\n",
        "    np.save(os.path.join(result_dir, 'val_des.npy'), val_des)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    if val_des.dtype not in [np.float32, np.float64]:\n",
        "      try:\n",
        "        val_des = val_des.astype(np.float32)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    del val_imgs\n",
        "    codebook = np.load(os.path.join(result_dir, 'codebook.npy'),\n",
        "                       allow_pickle=True)\n",
        "\n",
        "    print(\"Extract the image features...\")\n",
        "    start_time = time.time()\n",
        "    val_features = SpatialPyramid(val_des, codebook)\n",
        "    np.save(os.path.join(result_dir, 'val_features.npy'), val_features)\n",
        "    print(\"{:.4f} seconds\".format(time.time()-start_time))\n",
        "\n",
        "    del val_des, codebook\n",
        "\n",
        "    print('Test the classifiers...')\n",
        "    accuracy = 0\n",
        "    for class_name in tqdm(category):\n",
        "        target_idxs = np.array([read_txt(os.path.join(data_dir, '{}_val.txt'.format(class_name)))])\n",
        "        target_labels = get_labels(val_idxs, target_idxs)\n",
        "\n",
        "        val_accuracy = models[class_name].score(val_features, target_labels)\n",
        "        print('{} Classifier validation accuracy:  {:.4f}'.format(class_name, val_accuracy))\n",
        "        accuracy += val_accuracy\n",
        "\n",
        "    del val_features, target_idxs, target_labels\n",
        "\n",
        "    print('Average validation accuracy: {:.4f}'.format(accuracy/len(category)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS7Svvy2zTv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90bda83-9c52-45d9-cd05-941971388537"
      },
      "source": [
        "feat_params = {'extractor': DenseSIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'dsift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'linear'}\n",
        "models = SP_Trainer(feat_params, svm_params)\n",
        "SP_Test(feat_params, models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the training data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "2.3087 seconds\n",
            "Extract the local descriptors...\n",
            "0.2613 seconds\n",
            "Construct the bag of visual words...\n",
            "0.0029 seconds\n",
            "Extract the image features...\n",
            "50.0738 seconds\n",
            "Train the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:31<01:03, 31.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier train accuracy:  1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [00:57<00:28, 28.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse Classifier train accuracy:  1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [01:24<00:00, 28.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorbike Classifier train accuracy:  1.0000\n",
            "Average train accuracy: 1.0000\n",
            "Load the validation data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4698 seconds\n",
            "Extract the local descriptors...\n",
            "23.0163 seconds\n",
            "Extract the image features...\n",
            "61.5619 seconds\n",
            "Test the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:06<00:12,  6.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier validation accuracy:  0.8822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [00:33<00:18, 18.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse Classifier validation accuracy:  0.8170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:46<00:00, 15.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorbike Classifier validation accuracy:  0.8020\n",
            "Average validation accuracy: 0.8338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "401jsdB_8CA1"
      },
      "source": [
        "## Step 7: Classification using non-linear SVM\n",
        "Modifying the classifier using the non-linear SVM and evaluate the performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg162rmJ8Q8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb78789-93ff-429e-8ced-4c85d8f64b9e"
      },
      "source": [
        "feat_params = {'extractor': DenseSIFT_extraction, 'num_codewords':1024, 'result_dir':os.path.join(data_dir,'dsift_1024')}\n",
        "svm_params = {'C': 1, 'kernel': 'sigmoid'}\n",
        "\n",
        "models = Trainer(feat_params, svm_params)\n",
        "Test(feat_params, models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the training data...\n",
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "2.4460 seconds\n",
            "Successfully loaded the local descriptors\n",
            "Successfully loaded the bag of visual words\n",
            "Extract the image features...\n",
            "2.2834 seconds\n",
            "Train the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 2/3 [00:00<00:00, 11.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier train accuracy:  0.9084\n",
            "horse Classifier train accuracy:  0.8868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 3/3 [00:00<00:00, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorbike Classifier train accuracy:  0.8571\n",
            "Average train accuracy: 0.8841\n",
            "Load the validation data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 images missing: []/371\n",
            "0 images missing: []/399\n",
            "4.0932 seconds\n",
            "Extract the image features...\n",
            "2.3811 seconds\n",
            "Test the classifiers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 23.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane Classifier validation accuracy:  0.8471\n",
            "horse Classifier validation accuracy:  0.8045\n",
            "motorbike Classifier validation accuracy:  0.7494\n",
            "Average validation accuracy: 0.8003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}